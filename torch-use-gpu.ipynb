{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cbaad3-86be-4024-8486-ba1ae99c885b",
   "metadata": {},
   "source": [
    "# How to make use of GPU resources with PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52215703-b42f-4986-b8aa-7b69b1fc2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886428f5-927e-4ee8-acd7-b7171cba60aa",
   "metadata": {},
   "source": [
    "We can check to see if we have a GPU like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ae7609-a3ac-4c42-a723-5942ba35cbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()  # do we have a GPU? Should return True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd42b00-318f-4a7f-991b-6aea8162469c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()  # how many GPUs do we have access to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018d342-1674-4800-8bd1-e8a18f2d632c",
   "metadata": {},
   "source": [
    "## Now we know if we have a GPU device to use - let's use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcee4ed-1a94-4ca6-9b9a-d708a0e40d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# We'll assign the first GPU Device to our device variable.\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  # let's see what device we got"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6686219-275c-4ec0-909b-07d9934be4cb",
   "metadata": {},
   "source": [
    "If our print output is not 'cuda:0' - our environment is not set up correctly. Ensure you have loaded a GPU enable environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a4537e-0719-4335-b051-321e03d13268",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_568/1057824868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's see the name of our GPU!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \"\"\"\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0m_CudaDeviceProperties\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproperties\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m     \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will define _get_device_properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# let's see the name of our GPU!\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851d797-c6e3-4b70-92a4-30115307ac1d",
   "metadata": {},
   "source": [
    "### How to load vectors / matrices / data onto the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b73245d8-27e9-48fb-939f-ce952f4fe2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False , cpu\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.IntTensor([0, 30, 50, 75, 70])  # Initializing a Tensor of Ints\n",
    "print(X_train.is_cuda, \",\", X_train.device)  # Is tensor on GPU? Which device?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde4baa6-84a6-4c32-ab20-5be6d529a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False , cpu\n"
     ]
    }
   ],
   "source": [
    "# Move it to the device we want.\n",
    "X_train.to(device)\n",
    "# Now let's see!\n",
    "print(X_train.is_cuda, \",\", X_train.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947393c8-a9ac-42ff-a790-7a3b21d87763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False , cpu\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, we can initialize the tensor directly on Device.\n",
    "X_test = torch.IntTensor([30, 40, 50], device=device)\n",
    "print(X_test.is_cuda, \",\", X_test.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36b890-b52d-4968-838d-f749aa4d456f",
   "metadata": {},
   "source": [
    "### How to load a Neural Network Model onto the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ac26d2-8019-40ad-a659-985977c7fdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a basic fully connected neural network built in Torch.\n",
    "# If we want to load it / train it on our GPU, we must first put it on the GPU\n",
    "# Otherwise it will remain on CPU by default.\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 784)\n",
    "        self.fc2 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0545d521-be18-4623-9cbc-f6836e2126c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet().to(device)  # Now, the network is loaded onto our GPU!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
